{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "### Qualitative Features & Interaction Terms\n",
    "\n",
    "#### 1-A) Use the credit data set, fit OLS linear regression model to predict credit card balance using all the following features\n",
    " - Student\n",
    " - Income\n",
    " - Limit\n",
    " - Interaction term: Income*Student\n",
    " - Interaction term: Limit*Student\n",
    "\n",
    "#### Find the p-values of all features. Are they all helpful in predicting the response? Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                       0.953\n",
      "Model:                            OLS   Adj. R-squared:                  0.952\n",
      "Method:                 Least Squares   F-statistic:                     1583.\n",
      "Date:                Fri, 08 Feb 2019   Prob (F-statistic):          2.91e-258\n",
      "Time:                        21:18:34   Log-Likelihood:                -2409.6\n",
      "No. Observations:                 400   AIC:                             4831.\n",
      "Df Residuals:                     394   BIC:                             4855.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept              -415.3863     12.436    -33.401      0.000    -439.836    -390.936\n",
      "Student[T.Yes]          235.2261     41.256      5.702      0.000     154.117     316.336\n",
      "Income                   -7.6162      0.252    -30.272      0.000      -8.111      -7.122\n",
      "Income:Student[T.Yes]    -2.5835      0.702     -3.678      0.000      -3.965      -1.202\n",
      "Limit                     0.2613      0.004     69.090      0.000       0.254       0.269\n",
      "Limit:Student[T.Yes]      0.0667      0.012      5.515      0.000       0.043       0.090\n",
      "==============================================================================\n",
      "Omnibus:                       24.858   Durbin-Watson:                   1.906\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.166\n",
      "Skew:                           0.649   Prob(JB):                     7.65e-07\n",
      "Kurtosis:                       3.069   Cond. No.                     4.35e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.35e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "pvalues are:\n",
      "Intercept                5.549684e-117\n",
      "Student[T.Yes]            2.330768e-08\n",
      "Income                   7.366425e-105\n",
      "Income:Student[T.Yes]     2.680862e-04\n",
      "Limit                    2.626683e-222\n",
      "Limit:Student[T.Yes]      6.320226e-08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from pandas import read_csv\n",
    "\n",
    "credit =read_csv('Credit2.csv')\n",
    "\n",
    "#Add you code here\n",
    "#m1 has the terms without encoding for student.\n",
    "m1=smf.ols('Balance~Student+Income+Limit+Limit*Student+Income*Student',credit)\n",
    "f1=m1.fit()\n",
    "print(f1.summary())\n",
    "print('THE PVALUES ARE:')\n",
    "print(f1.pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender Student  \\\n",
       "0           1   14.891   3606     283      2   34         11    Male      No   \n",
       "1           2  106.025   6645     483      3   82         15  Female     Yes   \n",
       "2           3  104.593   7075     514      4   71         11    Male      No   \n",
       "3           4  148.924   9504     681      3   36         11  Female      No   \n",
       "4           5   55.882   4897     357      2   68         16    Male      No   \n",
       "\n",
       "  Married  Ethnicity  Balance  \n",
       "0     Yes  Caucasian      333  \n",
       "1     Yes      Asian      903  \n",
       "2      No      Asian      580  \n",
       "3      No      Asian      964  \n",
       "4     Yes  Caucasian      331  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the p values all of them are extremely low and we can see that Income and Limit seem like the best indicators by orders of magnitude compared to student status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The P Values are\n",
      "Intercept             5.549684e-117\n",
      "Studentcode            2.330768e-08\n",
      "Income                7.366425e-105\n",
      "Limit                 2.626683e-222\n",
      "Income:Studentcode     2.680862e-04\n",
      "Limit:Studentcode      6.320226e-08\n",
      "dtype: float64\n",
      "The Confident Intervals are:\n",
      "                             0           1\n",
      "Intercept          -439.836126 -390.936491\n",
      "Studentcode         154.116548  316.335654\n",
      "Income               -8.110814   -7.121541\n",
      "Limit                 0.253819    0.268687\n",
      "Income:Studentcode   -3.964548   -1.202384\n",
      "Limit:Studentcode     0.042914    0.090459\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                       0.953\n",
      "Model:                            OLS   Adj. R-squared:                  0.952\n",
      "Method:                 Least Squares   F-statistic:                     1583.\n",
      "Date:                Fri, 08 Feb 2019   Prob (F-statistic):          2.91e-258\n",
      "Time:                        19:34:25   Log-Likelihood:                -2409.6\n",
      "No. Observations:                 400   AIC:                             4831.\n",
      "Df Residuals:                     394   BIC:                             4855.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept           -415.3863     12.436    -33.401      0.000    -439.836    -390.936\n",
      "Studentcode          235.2261     41.256      5.702      0.000     154.117     316.336\n",
      "Income                -7.6162      0.252    -30.272      0.000      -8.111      -7.122\n",
      "Limit                  0.2613      0.004     69.090      0.000       0.254       0.269\n",
      "Income:Studentcode    -2.5835      0.702     -3.678      0.000      -3.965      -1.202\n",
      "Limit:Studentcode      0.0667      0.012      5.515      0.000       0.043       0.090\n",
      "==============================================================================\n",
      "Omnibus:                       24.858   Durbin-Watson:                   1.906\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.166\n",
      "Skew:                           0.649   Prob(JB):                     7.65e-07\n",
      "Kurtosis:                       3.069   Cond. No.                     4.35e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.35e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "credit['Studentcode'] = credit.Student.map({'No':0 , 'Yes':1})\n",
    "sm1=smf.ols('Balance~Studentcode+Income+Limit+Income*Studentcode+Limit*Studentcode',credit)\n",
    "fm1=sm1.fit()\n",
    "print('The P Values are')\n",
    "print(fm1.pvalues)\n",
    "print('The Confident Intervals are:')\n",
    "print(fm1.conf_int(alpha=0.05,cols=None))\n",
    "print(fm1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-B) Unsince sklearn library, find the test $R^2$ score for estimating the balance from features (Income, Limit, StudentEncode) using linear regression model. The StudentEncode is the binary feature that maps Student status to a numerical value ('yes' to 1 and 'No' to 0). \n",
    "- Set random state to zero in train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9492691755287224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9483051752240865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "credit =read_csv('Credit2.csv')\n",
    "\n",
    "credit['Studentcode'] = credit.Student.map({'No':0 , 'Yes':1})\n",
    "credit.head()\n",
    "#df=pd.DataFrame(credit,columns=['Income','Limit','StudentEncode','Balance'])\n",
    "#x=df[['Income','Limit','StudentEncode']]\n",
    "\n",
    "#y=df['Balance']\n",
    "\n",
    "#Unnamed: 0\tIncome\tLimit\tRating\tCards\tAge\tEducation\tGender\tStudent\tMarried\tEthnicity\tBalance\n",
    "#x=credit(['Income','Limit','StudentEncode'],axis=1,inplace=True)\n",
    "#x=credit(['Income','Limit','StudentEncode'])\n",
    "#creditfeatures=['Income','Limit','StudentEncode']\n",
    "#x=pd.DataFrame(credit,columns=creditfeatures)\n",
    "#y=pd.DataFrame(credit,columns=['Balance'])\n",
    "#y=credit(['Balance'],axis=1)\n",
    "#Add you code here\n",
    "x=pd.DataFrame(credit,columns=['Income','Limit','Studentcode'])\n",
    "y=pd.DataFrame(credit,columns=['Balance'])\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x, y, random_state=0)\n",
    "\n",
    "lm1=LinearRegression().fit(X_train,Y_train)\n",
    "# score\n",
    "print(lm1.score(X_test,Y_test))\n",
    "\n",
    "y_pred=lm1.predict(X_test)\n",
    "\n",
    "\n",
    "mean_squared_error(Y_test,y_pred)\n",
    "\n",
    "r2_score(lm1.predict(X_test),Y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-C) Repeat the above question after adding to the model the two interaction terms: (1) (Income x StudentEncode) and (2) (Limit x StudentEncode)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495744687195743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9490004310169586"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add you code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import patsy\n",
    "credit =read_csv('Credit2.csv')\n",
    "\n",
    "credit['Studentcode'] = credit.Student.map({'No':0 , 'Yes':1})\n",
    "credit.head()\n",
    "df=pd.DataFrame(credit,columns=['Income','Limit','Studentcode','Balance'])\n",
    "#x=df[['Income','Limit','StudentEncode']]\n",
    "\n",
    "#y=df['Balance']\n",
    "\n",
    "#Unnamed: 0\tIncome\tLimit\tRating\tCards\tAge\tEducation\tGender\tStudent\tMarried\tEthnicity\tBalance\n",
    "#x=credit(['Income','Limit','StudentEncode'],axis=1,inplace=True)\n",
    "#x=credit(['Income','Limit','StudentEncode'])\n",
    "#creditfeatures=['Income','Limit','StudentEncode']\n",
    "#x=pd.DataFrame(credit,columns=creditfeatures)\n",
    "#y=pd.DataFrame(credit,columns=['Balance'])\n",
    "#y=credit(['Balance'],axis=1)\n",
    "#Add you code here\n",
    "credit['IncomexStudentcode']=credit['Income']*credit['Studentcode']\n",
    "credit['LimitxStudentcode']=credit['Income']*credit['Studentcode']\n",
    "x=pd.DataFrame(credit,columns=['Income','Limit','Studentcode','IncomexStudentcode','LimitxStudentcode'])\n",
    "\n",
    "y=pd.DataFrame(credit,columns=['Balance'])\n",
    "\n",
    "#x,y=patsy.dmatrices('Balance ~ Studentcode +Income + Limit + Income*Studentcode+ Limit*Studentcode',credit)\n",
    "#y, X = patsy.dmatrices('Balance ~Studentcode +Income + Limit ', df, return_type=\"dataframe\")\n",
    "\n",
    "#y = np.ravel(y)\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x, y, random_state=0)\n",
    "\n",
    "lm1=LinearRegression().fit(X_train,Y_train)\n",
    "# score\n",
    "print(lm1.score(X_test,Y_test))\n",
    "\n",
    "y_pred=lm1.predict(X_test)\n",
    "\n",
    "mean_squared_error(Y_test,y_pred)\n",
    "\n",
    "r2_score(lm1.predict(X_test),Y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Polynomial Regression\n",
    "\n",
    "     Set random_state= 0 in train_test_split in all the questions below.\n",
    "\n",
    "#### 2-A) Use the Auto dataset, \n",
    "  - (i) Find the test $R^2$ metric of a linear regression model that predicts the miles per gallon (mpg) from the horsepower.\n",
    "\n",
    "  - (ii) Use polynomial regression to include both the horsepower feature and $(horsepower)^2$ in the regression model to predict the mpg. Find the test $R^2$ metric in this case\n",
    "\n",
    "Hint: You can use [numpy.concatenate](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html). For example to add to an array U a column vector $W^2$, we can use X=np.concatenate((U,W**2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6217658811398383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44185961646153726"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution for (A) \n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "AutoData=read_csv('Auto_modify.csv') # read the data\n",
    "#You will need AutoData.horsepower, and AutoData.mpg\n",
    "AutoData.head()\n",
    "#Add you code here\n",
    "AutoData['hp2']=AutoData['horsepower']*AutoData['horsepower']\n",
    "#here we are using horsepower and mpg\n",
    "x1=pd.DataFrame(AutoData,columns=['horsepower'])\n",
    "\n",
    "y1=pd.DataFrame(AutoData,columns=['mpg'])\n",
    "\n",
    "x1.head()\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x1, y1, random_state=0)\n",
    "\n",
    "lm1=LinearRegression().fit(X_train,Y_train)\n",
    "# score\n",
    "print(lm1.score(X_test,Y_test))\n",
    "\n",
    "y_pred=lm1.predict(X_test)\n",
    "\n",
    "mean_squared_error(Y_test,y_pred)\n",
    "\n",
    "r2_score(lm1.predict(X_test),Y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7271031504642004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6040248497540519"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2=pd.DataFrame(AutoData,columns=['horsepower','hp2'])\n",
    "y2=pd.DataFrame(AutoData,columns=['mpg'])\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x2, y2, random_state=0)\n",
    "# here we are using horsepower and horsepower^2 as the independent variables\n",
    "lm1=LinearRegression().fit(X_train,Y_train)\n",
    "# score\n",
    "print(lm1.score(X_test,Y_test))\n",
    "\n",
    "y_pred=lm1.predict(X_test)\n",
    "\n",
    "mean_squared_error(Y_test,y_pred)\n",
    "\n",
    "r2_score(lm1.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-B) With the same auto dataset, use KNN regression with K=7, to fit a model that predicts miles per gallon(mpg) in the following cases:\n",
    "\n",
    "- One feature: Horsepower only\n",
    "\n",
    "- Two features: horsepower and $(horsepower)^2$ \n",
    "\n",
    "#### Use MinMax feaures scaling. Find the $R^2$ metric in each of the above cases. Comparing KNN with linear regression, which model performs better? How does the performance change by adding the quadratic feature?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6609249833061158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "#Add your code here\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x1, y1, random_state=0)\n",
    "scaler=preprocessing.MinMaxScaler().fit(X_train)\n",
    "scaler2=preprocessing.MinMaxScaler().fit(Y_train)\n",
    "X_trainscaled=scaler.transform(X_train)\n",
    "X_testscaled=scaler.transform(X_test)\n",
    "knn1 = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "knn1.fit(X_trainscaled,Y_trainscaled)\n",
    "accuracy=knn1.score(X_testscaled,Y_testscaled)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6701084048823853\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "#Add your code here\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(x2, y2, random_state=0)\n",
    "scaler=preprocessing.MinMaxScaler().fit(X_train)\n",
    "scaler2=preprocessing.MinMaxScaler().fit(Y_train)\n",
    "X_trainscaled=scaler.transform(X_train)\n",
    "X_testscaled=scaler.transform(X_test)\n",
    "knn1 = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "knn1.fit(X_trainscaled,Y_trainscaled)\n",
    "accuracy=knn1.score(X_testscaled,Y_testscaled)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression performs considerably better than KNN regression when horsepower^2 is considered(Polynomial), while when horsepower is the only dependent variable KNN is slightly better than Linear regression.\n",
    "# this is probably because the shape of the response/mpg is more quadratic in nature with respect to horspower due to which polynomial regression works better.  In knn , this will have no effect as we are in effect considering neighbours and since minmax scaling has also been done, the effect of the quadratic term is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
